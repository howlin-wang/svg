
Our extensive experiments rigorously validate the feasibility and effectiveness of the proposed SVG model. We demonstrate its superior performance across multiple metrics, showcasing its efficiency, generative quality, and remarkable versatility compared to state-of-the-art baselines.

**Ultimate Efficiency: Unprecedented Speedup in Training and Inference**

SVG redefines efficiency in generative modeling. We observe substantial improvements in both training convergence and inference speed:

**Accelerated Training**: As illustrated in Figure 1(e), SVG-XL achieves a comparable FID-50K score to baseline models like SiT-XL in significantly fewer training epochs. Specifically, SVG achieves an impressive **62 times faster training** compared to existing VAE-based latent diffusion models. This drastic reduction in training time makes developing and iterating on generative models much more accessible.

**Rapid Inference**: Beyond training, SVG also excels at inference speed. As shown in Figure 1(f), SVG-XL produces high-quality samples with drastically fewer sampling steps. Our method enables **35 times faster inference** while maintaining superior generative quality, critical for real-time applications and user interaction.

> (Here you would embed Figure 1(e) and 1(f) from the paper, highlighting the speedup values)

**Superior Quality: High-Fidelity Image Generation**

SVG consistently delivers exceptional generative quality, rivaling and often surpassing leading VAE-based approaches.

**High-Quality Output**: Our model generates diverse and realistic images across a wide range of classes. Even with few-step sampling, SVG-XL produces images with remarkable fidelity and detail. Quantitative results in Table 1 and Table 2 demonstrate that SVG-XL achieves lower FID (FrÃ©chet Inception Distance) and higher Inception Scores (IS) than competitive baselines, indicating better perceptual quality and diversity.

**Visual Gallery**: Figures 2, and the supplementary figures 12 through 26 (if space permits) showcase a rich collection of SVG-XL generated samples, highlighting the model's ability to create visually compelling and diverse outputs across ImageNet 256x256.

> (Here you would embed Figure 2 from the paper, along with a curated selection of impressive samples from the supplementary materials)

**Powerful Versatility: A Unified Representation Across Vision Tasks**

A key advantage of SVG is its ability to create a truly unified feature space, breaking the mold of task-specific representations. The SVG encoder, primarily designed for generation, seamlessly transfers to various downstream perception and understanding tasks:

**Strong Generalization**: As detailed in Table 4, the SVG encoder, without any fine-tuning of its core weights (only a lightweight linear decoder is trained), achieves comparable or even superior results to the original DINOv3 encoder on a suite of tasks including ImageNet-1K classification, ADE20K semantic segmentation, and NYUv2 depth estimation.

**Dual-Purpose Power**: This demonstrates that the SVG feature space is not only optimal for efficient and high-quality image generation but also preserves the strong discriminative and semantic capabilities of its DINOv3 foundation, establishing it as a versatile foundation for diverse visual tasks.

> (Here you would embed Table 4 from the paper)

**Controllability: Zero-Shot Editing and Smooth Interpolation**

The well-structured and semantically rich SVG feature space also grants impressive control and manipulation capabilities:

**Zero-Shot Image Editing**: As shown in Figure 6, SVG enables coherent zero-shot class-conditioned image editing. Following an SDEdit-style procedure, SVG generates edits that accurately align with target class semantics while preserving consistency in non-edited regions, demonstrating the inherent editability and semantic structure of its latent space.

**Smooth Latent Space Interpolation**: Figure 7 illustrates the continuity of the SVG feature space. Both direct linear and spherical linear interpolations between noise vectors yield smooth, high-quality image transitions. This robustness, even under direct linear interpolation (where VAE-based methods typically degrade), highlights the superior geometry of the SVG latent space, facilitating meaningful and controllable image manipulations.

> (Here you would embed Figure 6 and Figure 7 from the paper)