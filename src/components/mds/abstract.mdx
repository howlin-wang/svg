# Abstract

Recent diffusion-based visual generation relies heavily on VAEs, which limit training efficiency, inference speed, and generalization due to poorly structured latent spaces. We propose SVG, a VAE-free latent diffusion model that leverages frozen DINO features to build a semantically discriminative latent space and a lightweight residual branch for fine details. Training directly in this space enables faster diffusion, few-step sampling, and high-fidelity generation, while preserving strong semantic and discriminative representations for broader vision tasks.